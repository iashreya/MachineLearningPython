{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,1]])\n",
    "test_data = np.array([[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    #Class Constructor\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1: ]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.eta = 100\n",
    "############################################################################################################################ \n",
    "\n",
    "    #Feedforwards the input 'a' and returns the activation of all nodes in network\n",
    "    def feedforward(self, a):\n",
    "        activations = []\n",
    "        a = np.transpose(a)\n",
    "        for b,w in zip(self.biases, self.weights):\n",
    "            activations.append(a)   \n",
    "            a = np.dot(w, a) + b\n",
    "        activations.append(a) \n",
    "        return activations\n",
    "############################################################################################################################\n",
    "    \n",
    "    #Takes as input both training and test sets and returns the activations of the output layer \n",
    "    def GD(self, training_data, test_data):\n",
    "        avg_activations = [0]\n",
    "        n = len(training_data[0])\n",
    "        #This iteration is for the model to adapt properly to the data\n",
    "        for i in range(100):\n",
    "            for i in training_data:\n",
    "                print(\"for training data : \", i)\n",
    "                x = np.array([i[0:n-1]])\n",
    "                temp_activations = self.feedforward(x)\n",
    "                b, w = self.backprop(temp_activations, i[n-1:])\n",
    "            \n",
    "                self.weights = np.array(self.weights)-w\n",
    "                self.biases = np.array(self.biases)-b\n",
    "                print(\"weights : \\t\", self.weights)\n",
    "                print(\"biases : \\t\", self.biases, \"\\n\")\n",
    "        z = self.feedforward(test_data)[-1]\n",
    "        return(self.sigmoid(z))\n",
    "    \n",
    "############################################################################################################################\n",
    "        \n",
    "    #Applies backpropagation and returns rate of change of cost with biases and weights\n",
    "    def backprop(self, activation, y):\n",
    "        l = len(activation)-1\n",
    "        delta = [((activation[l])-y)*self.sigmoid_prime(activation[l])]\n",
    "        for i in range(self.num_layers-2):\n",
    "            temp = (np.dot(np.transpose(self.weights[l-i-1]),delta[i]))*self.sigmoid_prime(activation[l-i-1])\n",
    "            delta.append(temp)\n",
    "        b = delta\n",
    "        w = []\n",
    "        for i in range(self.num_layers-1):\n",
    "            temp = np.dot(activation[l-i-1],np.transpose(delta[i]))\n",
    "            w.append(temp) \n",
    "            \n",
    "        lst = []\n",
    "        for i in range(len(w)):\n",
    "            x = np.transpose(np.array(w[len(w)-i-1]))\n",
    "            lst.append(self.eta*x/4)\n",
    "        w = lst\n",
    "\n",
    "        lst = []\n",
    "        for i in range(len(b)):\n",
    "            x = np.array(b[len(b)-i-1])\n",
    "            lst.append(self.eta*x/4)\n",
    "            b = lst     \n",
    "        return(b, w)\n",
    "    \n",
    "############################################################################################################################    \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        lst = []\n",
    "        for i in z:\n",
    "            x = 1.0/(1.0+np.exp(-i))\n",
    "            lst.append(x)\n",
    "        return( np.array(lst))\n",
    "\n",
    "############################################################################################################################\n",
    "    \n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Network([2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-0.52314892 -0.3733839 ]]]\n",
      "biases : \t [[[-3.75272362]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-0.52314892  1.63048871]]]\n",
      "biases : \t [[[-1.74885102]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.40794763  1.63048871]]]\n",
      "biases : \t [[[ 5.18224553]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.40739382  1.62993489]]]\n",
      "biases : \t [[[ 5.18169171]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.40739382  1.62993489]]]\n",
      "biases : \t [[[ 4.46196942]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.40739382  1.34339964]]]\n",
      "biases : \t [[[ 4.17543416]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.40132159  1.34339964]]]\n",
      "biases : \t [[[ 4.16936193]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.39949475  1.34157279]]]\n",
      "biases : \t [[[ 4.16753509]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.39949475  1.34157279]]]\n",
      "biases : \t [[[ 2.60247816]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.39949475 -0.03039026]]]\n",
      "biases : \t [[[ 1.23051511]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.31907527 -0.03039026]]]\n",
      "biases : \t [[[ 1.15009562]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.22453612 -0.12492941]]]\n",
      "biases : \t [[[ 1.05555648]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.22453612 -0.12492941]]]\n",
      "biases : \t [[[-3.99826819]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.22453612  1.88345596]]]\n",
      "biases : \t [[[-1.98988282]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 5.08641084  1.88345596]]]\n",
      "biases : \t [[[-3.1280081]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 3.6255559   0.42260101]]]\n",
      "biases : \t [[[-4.58886305]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 3.6255559   0.42260101]]]\n",
      "biases : \t [[[-3.44613449]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 3.6255559   4.87096099]]]\n",
      "biases : \t [[[ 1.00222549]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 2.7559735   4.87096099]]]\n",
      "biases : \t [[[ 0.13264309]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 2.68393787  4.79892537]]]\n",
      "biases : \t [[[ 0.06060746]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 2.68393787  4.79892537]]]\n",
      "biases : \t [[[-0.31784152]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 2.68393787  3.83561477]]]\n",
      "biases : \t [[[-1.28115212]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 1.08872743  3.83561477]]]\n",
      "biases : \t [[[-2.87636255]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[-1.56271598  1.18417136]]]\n",
      "biases : \t [[[-5.52780597]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-1.56271598  1.18417136]]]\n",
      "biases : \t [[[-4.98286227]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-1.56271598  3.75498466]]]\n",
      "biases : \t [[[-2.41204897]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 0.68804874  3.75498466]]]\n",
      "biases : \t [[[-0.16128425]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[-0.41497526  2.65196066]]]\n",
      "biases : \t [[[-1.26430825]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-0.41497526  2.65196066]]]\n",
      "biases : \t [[[ 4.16369912]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-0.41497526  2.49289233]]]\n",
      "biases : \t [[[ 4.0046308]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[-2.10759577  2.49289233]]]\n",
      "biases : \t [[[ 2.31201028]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[-4.61735047 -0.01686237]]]\n",
      "biases : \t [[[-0.19774442]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-4.61735047 -0.01686237]]]\n",
      "biases : \t [[[ 1.02615469]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-4.61735047 -0.06234039]]]\n",
      "biases : \t [[[ 0.98067667]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[-1.71882689 -0.06234039]]]\n",
      "biases : \t [[[ 3.87920026]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[-4.39100687 -2.73452037]]]\n",
      "biases : \t [[[ 1.20702028]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-4.39100687 -2.73452037]]]\n",
      "biases : \t [[[-4.14078709]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-4.39100687 -2.53156401]]]\n",
      "biases : \t [[[-3.93783073]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[-4.33472226 -2.53156401]]]\n",
      "biases : \t [[[-3.88154612]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[-4.32841044 -2.52525218]]]\n",
      "biases : \t [[[-3.8752343]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[-4.32841044 -2.52525218]]]\n",
      "biases : \t [[[-1.94590318]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-4.32841044 -0.99646943]]]\n",
      "biases : \t [[[-0.41712043]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[-3.10154626 -0.99646943]]]\n",
      "biases : \t [[[ 0.80974375]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 0.61654381  2.72162064]]]\n",
      "biases : \t [[[ 4.52783382]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 0.61654381  2.72162064]]]\n",
      "biases : \t [[[ 3.33086375]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 0.61654381  2.4259257 ]]]\n",
      "biases : \t [[[ 3.03516881]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[-1.01763006  2.4259257 ]]]\n",
      "biases : \t [[[ 1.40099494]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ -3.44186240e+00   1.69336415e-03]]]\n",
      "biases : \t [[[-1.0232374]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ -3.44186240e+00   1.69336415e-03]]]\n",
      "biases : \t [[[ 3.95203332]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[-3.4418624  -1.36202354]]]\n",
      "biases : \t [[[ 2.58831642]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26488437 -1.36202354]]]\n",
      "biases : \t [[[ 12.2950632]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26487062 -1.36203729]]]\n",
      "biases : \t [[[ 12.29504944]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26487062 -1.36203729]]]\n",
      "biases : \t [[[ 12.29364341]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26487062 -1.36647754]]]\n",
      "biases : \t [[[ 12.28920316]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26486678 -1.36647754]]]\n",
      "biases : \t [[[ 12.28919932]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26485289 -1.36649143]]]\n",
      "biases : \t [[[ 12.28918543]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26485289 -1.36649143]]]\n",
      "biases : \t [[[ 12.28777181]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26485289 -1.37097311]]]\n",
      "biases : \t [[[ 12.28329014]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26484903 -1.37097311]]]\n",
      "biases : \t [[[ 12.28328627]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.264835   -1.37098713]]]\n",
      "biases : \t [[[ 12.28327225]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.264835   -1.37098713]]]\n",
      "biases : \t [[[ 12.28185093]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.264835   -1.37551098]]]\n",
      "biases : \t [[[ 12.27732708]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26483112 -1.37551098]]]\n",
      "biases : \t [[[ 12.2773232]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26481695 -1.37552514]]]\n",
      "biases : \t [[[ 12.27730903]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26481695 -1.37552514]]]\n",
      "biases : \t [[[ 12.2758799]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26481695 -1.38009193]]]\n",
      "biases : \t [[[ 12.27131312]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26481305 -1.38009193]]]\n",
      "biases : \t [[[ 12.27130921]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26479874 -1.38010623]]]\n",
      "biases : \t [[[ 12.2712949]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26479874 -1.38010623]]]\n",
      "biases : \t [[[ 12.26985786]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26479874 -1.38471675]]]\n",
      "biases : \t [[[ 12.26524734]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26479481 -1.38471675]]]\n",
      "biases : \t [[[ 12.26524341]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26478036 -1.3847312 ]]]\n",
      "biases : \t [[[ 12.26522896]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26478036 -1.3847312 ]]]\n",
      "biases : \t [[[ 12.26378388]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26478036 -1.38938628]]]\n",
      "biases : \t [[[ 12.25912881]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26477641 -1.38938628]]]\n",
      "biases : \t [[[ 12.25912486]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26476182 -1.38940087]]]\n",
      "biases : \t [[[ 12.25911026]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26476182 -1.38940087]]]\n",
      "biases : \t [[[ 12.25765704]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26476182 -1.39410133]]]\n",
      "biases : \t [[[ 12.25295659]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26475784 -1.39410133]]]\n",
      "biases : \t [[[ 12.25295261]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26474309 -1.39411608]]]\n",
      "biases : \t [[[ 12.25293786]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26474309 -1.39411608]]]\n",
      "biases : \t [[[ 12.25147638]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26474309 -1.39886278]]]\n",
      "biases : \t [[[ 12.24672968]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2647391  -1.39886278]]]\n",
      "biases : \t [[[ 12.24672568]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2647242  -1.39887768]]]\n",
      "biases : \t [[[ 12.24671078]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2647242  -1.39887768]]]\n",
      "biases : \t [[[ 12.24524092]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2647242  -1.40367152]]]\n",
      "biases : \t [[[ 12.24044708]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26472017 -1.40367152]]]\n",
      "biases : \t [[[ 12.24044306]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26470512 -1.40368658]]]\n",
      "biases : \t [[[ 12.240428]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26470512 -1.40368658]]]\n",
      "biases : \t [[[ 12.23894964]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26470512 -1.40852846]]]\n",
      "biases : \t [[[ 12.23410776]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26470107 -1.40852846]]]\n",
      "biases : \t [[[ 12.23410371]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26468586 -1.40854367]]]\n",
      "biases : \t [[[ 12.2340885]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26468586 -1.40854367]]]\n",
      "biases : \t [[[ 12.2326015]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26468586 -1.41343453]]]\n",
      "biases : \t [[[ 12.22771064]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26468179 -1.41343453]]]\n",
      "biases : \t [[[ 12.22770657]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26466641 -1.41344991]]]\n",
      "biases : \t [[[ 12.22769119]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26466641 -1.41344991]]]\n",
      "biases : \t [[[ 12.22619544]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26466641 -1.41839071]]]\n",
      "biases : \t [[[ 12.22125463]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26466231 -1.41839071]]]\n",
      "biases : \t [[[ 12.22125054]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26464677 -1.41840625]]]\n",
      "biases : \t [[[ 12.221235]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26464677 -1.41840625]]]\n",
      "biases : \t [[[ 12.21973034]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26464677 -1.42339799]]]\n",
      "biases : \t [[[ 12.21473861]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26464265 -1.42339799]]]\n",
      "biases : \t [[[ 12.21473449]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26462694 -1.4234137 ]]]\n",
      "biases : \t [[[ 12.21471877]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26462694 -1.4234137 ]]]\n",
      "biases : \t [[[ 12.21320509]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26462694 -1.4284574 ]]]\n",
      "biases : \t [[[ 12.2081614]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26462279 -1.4284574 ]]]\n",
      "biases : \t [[[ 12.20815725]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2646069  -1.42847328]]]\n",
      "biases : \t [[[ 12.20814137]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2646069  -1.42847328]]]\n",
      "biases : \t [[[ 12.20661852]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2646069  -1.43356998]]]\n",
      "biases : \t [[[ 12.20152182]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26460273 -1.43356998]]]\n",
      "biases : \t [[[ 12.20151764]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26458667 -1.43358605]]]\n",
      "biases : \t [[[ 12.20150158]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26458667 -1.43358605]]]\n",
      "biases : \t [[[ 12.19996942]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26458667 -1.43873685]]]\n",
      "biases : \t [[[ 12.19481862]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26458247 -1.43873685]]]\n",
      "biases : \t [[[ 12.19481442]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26456623 -1.43875309]]]\n",
      "biases : \t [[[ 12.19479818]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26456623 -1.43875309]]]\n",
      "biases : \t [[[ 12.19325656]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26456623 -1.4439591 ]]]\n",
      "biases : \t [[[ 12.18805055]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.264562  -1.4439591]]]\n",
      "biases : \t [[[ 12.18804633]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26454558 -1.44397552]]]\n",
      "biases : \t [[[ 12.1880299]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26454558 -1.44397552]]]\n",
      "biases : \t [[[ 12.18647867]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26454558 -1.4492379 ]]]\n",
      "biases : \t [[[ 12.1812163]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26454132 -1.4492379 ]]]\n",
      "biases : \t [[[ 12.18121204]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26452471 -1.44925452]]]\n",
      "biases : \t [[[ 12.18119543]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26452471 -1.44925452]]]\n",
      "biases : \t [[[ 12.17963444]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26452471 -1.45457445]]]\n",
      "biases : \t [[[ 12.17431451]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26452043 -1.45457445]]]\n",
      "biases : \t [[[ 12.17431023]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26450362 -1.45459125]]]\n",
      "biases : \t [[[ 12.17429342]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26450362 -1.45459125]]]\n",
      "biases : \t [[[ 12.17272252]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26450362 -1.45996996]]]\n",
      "biases : \t [[[ 12.1673438]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26449931 -1.45996996]]]\n",
      "biases : \t [[[ 12.16733949]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26448231 -1.45998697]]]\n",
      "biases : \t [[[ 12.16732249]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26448231 -1.45998697]]]\n",
      "biases : \t [[[ 12.1657415]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26448231 -1.46542573]]]\n",
      "biases : \t [[[ 12.16030274]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26447797 -1.46542573]]]\n",
      "biases : \t [[[ 12.1602984]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26446077 -1.46544293]]]\n",
      "biases : \t [[[ 12.1602812]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26446077 -1.46544293]]]\n",
      "biases : \t [[[ 12.15868996]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26446077 -1.47094304]]]\n",
      "biases : \t [[[ 12.15318985]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2644564  -1.47094304]]]\n",
      "biases : \t [[[ 12.15318548]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26443899 -1.47096045]]]\n",
      "biases : \t [[[ 12.15316807]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26443899 -1.47096045]]]\n",
      "biases : \t [[[ 12.15156641]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26443899 -1.47652326]]]\n",
      "biases : \t [[[ 12.1460036]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26443459 -1.47652326]]]\n",
      "biases : \t [[[ 12.1459992]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26441698 -1.47654088]]]\n",
      "biases : \t [[[ 12.14598158]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26441698 -1.47654088]]]\n",
      "biases : \t [[[ 12.14436932]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26441698 -1.48216778]]]\n",
      "biases : \t [[[ 12.13874242]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26441255 -1.48216778]]]\n",
      "biases : \t [[[ 12.13873799]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26439472 -1.48218562]]]\n",
      "biases : \t [[[ 12.13872016]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26439472 -1.48218562]]]\n",
      "biases : \t [[[ 12.13709712]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26439472 -1.48787806]]]\n",
      "biases : \t [[[ 12.13140468]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26439026 -1.48787806]]]\n",
      "biases : \t [[[ 12.13140022]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2643722  -1.48789611]]]\n",
      "biases : \t [[[ 12.13138217]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2643722  -1.48789611]]]\n",
      "biases : \t [[[ 12.12974816]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2643722  -1.49365557]]]\n",
      "biases : \t [[[ 12.1239887]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26436771 -1.49365557]]]\n",
      "biases : \t [[[ 12.12398421]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26434944 -1.49367385]]]\n",
      "biases : \t [[[ 12.12396593]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26434944 -1.49367385]]]\n",
      "biases : \t [[[ 12.12232077]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26434944 -1.49950188]]]\n",
      "biases : \t [[[ 12.11649274]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26434492 -1.49950188]]]\n",
      "biases : \t [[[ 12.11648822]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26432641 -1.49952039]]]\n",
      "biases : \t [[[ 12.11646971]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26432641 -1.49952039]]]\n",
      "biases : \t [[[ 12.1148132]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26432641 -1.50541857]]]\n",
      "biases : \t [[[ 12.10891501]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26432185 -1.50541857]]]\n",
      "biases : \t [[[ 12.10891046]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26430311 -1.50543731]]]\n",
      "biases : \t [[[ 12.10889172]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26430311 -1.50543731]]]\n",
      "biases : \t [[[ 12.10722364]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26430311 -1.51140729]]]\n",
      "biases : \t [[[ 12.10125366]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26429852 -1.51140729]]]\n",
      "biases : \t [[[ 12.10124907]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26427954 -1.51142628]]]\n",
      "biases : \t [[[ 12.10123009]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26427954 -1.51142628]]]\n",
      "biases : \t [[[ 12.09955025]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26427954 -1.51746977]]]\n",
      "biases : \t [[[ 12.09350676]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26427492 -1.51746977]]]\n",
      "biases : \t [[[ 12.09350214]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26425568 -1.517489  ]]]\n",
      "biases : \t [[[ 12.0934829]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26425568 -1.517489  ]]]\n",
      "biases : \t [[[ 12.09179109]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26425568 -1.52360777]]]\n",
      "biases : \t [[[ 12.08567232]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26425103 -1.52360777]]]\n",
      "biases : \t [[[ 12.08566766]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26423154 -1.52362726]]]\n",
      "biases : \t [[[ 12.08564818]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26423154 -1.52362726]]]\n",
      "biases : \t [[[ 12.08394416]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26423154 -1.52982313]]]\n",
      "biases : \t [[[ 12.07774829]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26422685 -1.52982313]]]\n",
      "biases : \t [[[ 12.07774359]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2642071  -1.52984288]]]\n",
      "biases : \t [[[ 12.07772385]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2642071  -1.52984288]]]\n",
      "biases : \t [[[ 12.0760074]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2642071  -1.53611775]]]\n",
      "biases : \t [[[ 12.06973252]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26420238 -1.53611775]]]\n",
      "biases : \t [[[ 12.0697278]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26418236 -1.53613777]]]\n",
      "biases : \t [[[ 12.06970778]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26418236 -1.53613777]]]\n",
      "biases : \t [[[ 12.06797867]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26418236 -1.54249361]]]\n",
      "biases : \t [[[ 12.06162282]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2641776  -1.54249361]]]\n",
      "biases : \t [[[ 12.06161806]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26415731 -1.5425139 ]]]\n",
      "biases : \t [[[ 12.06159777]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26415731 -1.5425139 ]]]\n",
      "biases : \t [[[ 12.05985574]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26415731 -1.54895275]]]\n",
      "biases : \t [[[ 12.05341689]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26415251 -1.54895275]]]\n",
      "biases : \t [[[ 12.05341209]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26413194 -1.54897332]]]\n",
      "biases : \t [[[ 12.05339152]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26413194 -1.54897332]]]\n",
      "biases : \t [[[ 12.05163634]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26413194 -1.55549731]]]\n",
      "biases : \t [[[ 12.04511235]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2641271  -1.55549731]]]\n",
      "biases : \t [[[ 12.04510752]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26410625 -1.55551816]]]\n",
      "biases : \t [[[ 12.04508666]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26410625 -1.55551816]]]\n",
      "biases : \t [[[ 12.04331806]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26410625 -1.56212948]]]\n",
      "biases : \t [[[ 12.03670674]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26410137 -1.56212948]]]\n",
      "biases : \t [[[ 12.03670187]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26408022 -1.56215063]]]\n",
      "biases : \t [[[ 12.03668071]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26408022 -1.56215063]]]\n",
      "biases : \t [[[ 12.03489843]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26408022 -1.56885156]]]\n",
      "biases : \t [[[ 12.0281975]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2640753  -1.56885156]]]\n",
      "biases : \t [[[ 12.02819258]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26405384 -1.56887302]]]\n",
      "biases : \t [[[ 12.02817113]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26405384 -1.56887302]]]\n",
      "biases : \t [[[ 12.02637488]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26405384 -1.57566593]]]\n",
      "biases : \t [[[ 12.01958196]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26404889 -1.57566593]]]\n",
      "biases : \t [[[ 12.01957701]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26402712 -1.5756877 ]]]\n",
      "biases : \t [[[ 12.01955524]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26402712 -1.5756877 ]]]\n",
      "biases : \t [[[ 12.01774475]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26402712 -1.58257507]]]\n",
      "biases : \t [[[ 12.01085737]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26402212 -1.58257507]]]\n",
      "biases : \t [[[ 12.01085238]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26400003 -1.58259717]]]\n",
      "biases : \t [[[ 12.01083028]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26400003 -1.58259717]]]\n",
      "biases : \t [[[ 12.00900525]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26400003 -1.58958156]]]\n",
      "biases : \t [[[ 12.00202085]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26399499 -1.58958156]]]\n",
      "biases : \t [[[ 12.00201582]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26397256 -1.58960399]]]\n",
      "biases : \t [[[ 12.00199339]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26397256 -1.58960399]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biases : \t [[[ 12.00015352]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26397256 -1.59668809]]]\n",
      "biases : \t [[[ 11.99306942]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26396748 -1.59668809]]]\n",
      "biases : \t [[[ 11.99306434]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26394472 -1.59671085]]]\n",
      "biases : \t [[[ 11.99304157]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26394472 -1.59671085]]]\n",
      "biases : \t [[[ 11.99118654]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26394472 -1.60389744]]]\n",
      "biases : \t [[[ 11.98399995]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26393959 -1.60389744]]]\n",
      "biases : \t [[[ 11.98399483]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26391648 -1.60392055]]]\n",
      "biases : \t [[[ 11.98397171]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26391648 -1.60392055]]]\n",
      "biases : \t [[[ 11.98210119]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26391648 -1.61121252]]]\n",
      "biases : \t [[[ 11.97480922]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26391131 -1.61121252]]]\n",
      "biases : \t [[[ 11.97480405]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26388784 -1.611236  ]]]\n",
      "biases : \t [[[ 11.97478057]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26388784 -1.611236  ]]]\n",
      "biases : \t [[[ 11.97289423]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26388784 -1.61863638]]]\n",
      "biases : \t [[[ 11.96549385]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26388262 -1.61863638]]]\n",
      "biases : \t [[[ 11.96548863]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26385877 -1.61866023]]]\n",
      "biases : \t [[[ 11.96546478]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26385877 -1.61866023]]]\n",
      "biases : \t [[[ 11.96356227]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26385877 -1.62617218]]]\n",
      "biases : \t [[[ 11.95605031]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26385351 -1.62617218]]]\n",
      "biases : \t [[[ 11.95604505]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26382928 -1.62619641]]]\n",
      "biases : \t [[[ 11.95602082]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26382928 -1.62619641]]]\n",
      "biases : \t [[[ 11.95410177]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26382928 -1.63382323]]]\n",
      "biases : \t [[[ 11.94647495]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26382397 -1.63382323]]]\n",
      "biases : \t [[[ 11.94646964]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26379935 -1.63384785]]]\n",
      "biases : \t [[[ 11.94644502]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26379935 -1.63384785]]]\n",
      "biases : \t [[[ 11.94450905]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26379935 -1.64159298]]]\n",
      "biases : \t [[[ 11.93676392]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26379399 -1.64159298]]]\n",
      "biases : \t [[[ 11.93675857]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26376896 -1.64161801]]]\n",
      "biases : \t [[[ 11.93673354]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26376896 -1.64161801]]]\n",
      "biases : \t [[[ 11.93478027]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26376896 -1.64948503]]]\n",
      "biases : \t [[[ 11.92691324]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26376355 -1.64948503]]]\n",
      "biases : \t [[[ 11.92690783]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2637381  -1.64951048]]]\n",
      "biases : \t [[[ 11.92688238]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2637381  -1.64951048]]]\n",
      "biases : \t [[[ 11.9249114]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2637381  -1.65750317]]]\n",
      "biases : \t [[[ 11.91691872]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26373264 -1.65750317]]]\n",
      "biases : \t [[[ 11.91691325]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26370676 -1.65752905]]]\n",
      "biases : \t [[[ 11.91688737]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26370676 -1.65752905]]]\n",
      "biases : \t [[[ 11.91489826]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26370676 -1.66565134]]]\n",
      "biases : \t [[[ 11.90677598]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26370125 -1.66565134]]]\n",
      "biases : \t [[[ 11.90677046]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26367492 -1.66567767]]]\n",
      "biases : \t [[[ 11.90674413]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26367492 -1.66567767]]]\n",
      "biases : \t [[[ 11.90473646]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26367492 -1.67393367]]]\n",
      "biases : \t [[[ 11.89648045]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26366935 -1.67393367]]]\n",
      "biases : \t [[[ 11.89647488]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26364256 -1.67396046]]]\n",
      "biases : \t [[[ 11.89644809]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26364256 -1.67396046]]]\n",
      "biases : \t [[[ 11.89442139]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26364256 -1.68235451]]]\n",
      "biases : \t [[[ 11.88602735]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26363694 -1.68235451]]]\n",
      "biases : \t [[[ 11.88602173]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26360967 -1.68238178]]]\n",
      "biases : \t [[[ 11.88599446]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26360967 -1.68238178]]]\n",
      "biases : \t [[[ 11.88394826]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26360967 -1.69091839]]]\n",
      "biases : \t [[[ 11.87541165]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26360399 -1.69091839]]]\n",
      "biases : \t [[[ 11.87540597]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26357622 -1.69094616]]]\n",
      "biases : \t [[[ 11.8753782]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26357622 -1.69094616]]]\n",
      "biases : \t [[[ 11.87331201]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26357622 -1.69963009]]]\n",
      "biases : \t [[[ 11.86462808]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26357048 -1.69963009]]]\n",
      "biases : \t [[[ 11.86462234]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26354221 -1.69965836]]]\n",
      "biases : \t [[[ 11.86459407]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26354221 -1.69965836]]]\n",
      "biases : \t [[[ 11.86250737]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26354221 -1.70849461]]]\n",
      "biases : \t [[[ 11.85367112]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26353641 -1.70849461]]]\n",
      "biases : \t [[[ 11.85366533]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2635076  -1.70852342]]]\n",
      "biases : \t [[[ 11.85363652]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2635076  -1.70852342]]]\n",
      "biases : \t [[[ 11.85152878]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2635076  -1.71751722]]]\n",
      "biases : \t [[[ 11.84253498]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26350175 -1.71751722]]]\n",
      "biases : \t [[[ 11.84252912]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26347239 -1.71754658]]]\n",
      "biases : \t [[[ 11.84249976]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26347239 -1.71754658]]]\n",
      "biases : \t [[[ 11.84037042]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26347239 -1.72670347]]]\n",
      "biases : \t [[[ 11.83121354]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26346647 -1.72670347]]]\n",
      "biases : \t [[[ 11.83120762]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26343654 -1.72673339]]]\n",
      "biases : \t [[[ 11.83117769]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26343654 -1.72673339]]]\n",
      "biases : \t [[[ 11.82902617]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26343654 -1.73605917]]]\n",
      "biases : \t [[[ 11.81970038]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26343056 -1.73605917]]]\n",
      "biases : \t [[[ 11.8196944]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26340004 -1.73608969]]]\n",
      "biases : \t [[[ 11.81966388]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26340004 -1.73608969]]]\n",
      "biases : \t [[[ 11.81748956]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26340004 -1.74559049]]]\n",
      "biases : \t [[[ 11.80798876]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26339399 -1.74559049]]]\n",
      "biases : \t [[[ 11.80798271]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26336286 -1.74562162]]]\n",
      "biases : \t [[[ 11.80795158]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26336286 -1.74562162]]]\n",
      "biases : \t [[[ 11.80575382]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26336286 -1.75530389]]]\n",
      "biases : \t [[[ 11.79607155]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26335674 -1.75530389]]]\n",
      "biases : \t [[[ 11.79606542]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26332498 -1.75533566]]]\n",
      "biases : \t [[[ 11.79603366]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26332498 -1.75533566]]]\n",
      "biases : \t [[[ 11.7938118]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26332498 -1.76520624]]]\n",
      "biases : \t [[[ 11.78394122]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26331879 -1.76520624]]]\n",
      "biases : \t [[[ 11.78393503]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26328636 -1.76523866]]]\n",
      "biases : \t [[[ 11.7839026]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26328636 -1.76523866]]]\n",
      "biases : \t [[[ 11.78165594]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26328636 -1.77530475]]]\n",
      "biases : \t [[[ 11.77158985]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26328009 -1.77530475]]]\n",
      "biases : \t [[[ 11.77158359]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26324698 -1.77533786]]]\n",
      "biases : \t [[[ 11.77155047]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26324698 -1.77533786]]]\n",
      "biases : \t [[[ 11.76927827]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26324698 -1.78560708]]]\n",
      "biases : \t [[[ 11.75900905]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26324064 -1.78560708]]]\n",
      "biases : \t [[[ 11.75900272]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2632068  -1.78564091]]]\n",
      "biases : \t [[[ 11.75896888]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2632068  -1.78564091]]]\n",
      "biases : \t [[[ 11.75667037]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2632068  -1.79612133]]]\n",
      "biases : \t [[[ 11.74618995]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26320039 -1.79612133]]]\n",
      "biases : \t [[[ 11.74618353]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26316581 -1.79615591]]]\n",
      "biases : \t [[[ 11.74614895]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26316581 -1.79615591]]]\n",
      "biases : \t [[[ 11.74382332]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26316581 -1.80685609]]]\n",
      "biases : \t [[[ 11.73312314]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26315931 -1.80685609]]]\n",
      "biases : \t [[[ 11.73311664]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26312395 -1.80689145]]]\n",
      "biases : \t [[[ 11.73308128]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26312395 -1.80689145]]]\n",
      "biases : \t [[[ 11.73072768]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26312395 -1.81782048]]]\n",
      "biases : \t [[[ 11.71979865]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26311738 -1.81782048]]]\n",
      "biases : \t [[[ 11.71979207]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.2630812  -1.81785666]]]\n",
      "biases : \t [[[ 11.7197559]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.2630812  -1.81785666]]]\n",
      "biases : \t [[[ 11.71737344]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.2630812  -1.82902419]]]\n",
      "biases : \t [[[ 11.7062059]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26307454 -1.82902419]]]\n",
      "biases : \t [[[ 11.70619924]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26303752 -1.82906121]]]\n",
      "biases : \t [[[ 11.70616222]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26303752 -1.82906121]]]\n",
      "biases : \t [[[ 11.70374995]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26303752 -1.84047752]]]\n",
      "biases : \t [[[ 11.69233364]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26303077 -1.84047752]]]\n",
      "biases : \t [[[ 11.69232689]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26299286 -1.84051543]]]\n",
      "biases : \t [[[ 11.69228898]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26299286 -1.84051543]]]\n",
      "biases : \t [[[ 11.68984592]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26299286 -1.85219144]]]\n",
      "biases : \t [[[ 11.6781699]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26298602 -1.85219144]]]\n",
      "biases : \t [[[ 11.67816306]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26294718 -1.85223028]]]\n",
      "biases : \t [[[ 11.67812422]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26294718 -1.85223028]]]\n",
      "biases : \t [[[ 11.6756493]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26294718 -1.86417768]]]\n",
      "biases : \t [[[ 11.66370191]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26294025 -1.86417768]]]\n",
      "biases : \t [[[ 11.66369497]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26290044 -1.86421749]]]\n",
      "biases : \t [[[ 11.66365516]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26290044 -1.86421749]]]\n",
      "biases : \t [[[ 11.66114729]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26290044 -1.87644872]]]\n",
      "biases : \t [[[ 11.64891605]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2628934  -1.87644872]]]\n",
      "biases : \t [[[ 11.64890902]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26285257 -1.87648955]]]\n",
      "biases : \t [[[ 11.64886819]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26285257 -1.87648955]]]\n",
      "biases : \t [[[ 11.64632618]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26285257 -1.88901796]]]\n",
      "biases : \t [[[ 11.63379778]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26284544 -1.88901796]]]\n",
      "biases : \t [[[ 11.63379064]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26280354 -1.88905986]]]\n",
      "biases : \t [[[ 11.63374874]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26280354 -1.88905986]]]\n",
      "biases : \t [[[ 11.63117136]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26280354 -1.90189971]]]\n",
      "biases : \t [[[ 11.6183315]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.2627963  -1.90189971]]]\n",
      "biases : \t [[[ 11.61832426]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26275327 -1.90194274]]]\n",
      "biases : \t [[[ 11.61828124]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26275327 -1.90194274]]]\n",
      "biases : \t [[[ 11.61566716]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26275327 -1.91510936]]]\n",
      "biases : \t [[[ 11.60250054]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26274592 -1.91510936]]]\n",
      "biases : \t [[[ 11.60249319]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26270171 -1.91515357]]]\n",
      "biases : \t [[[ 11.60244898]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26270171 -1.91515357]]]\n",
      "biases : \t [[[ 11.5997968]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26270171 -1.92866343]]]\n",
      "biases : \t [[[ 11.58628694]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26269425 -1.92866343]]]\n",
      "biases : \t [[[ 11.58627948]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26264879 -1.92870889]]]\n",
      "biases : \t [[[ 11.58623402]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26264879 -1.92870889]]]\n",
      "biases : \t [[[ 11.58354226]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26264879 -1.94257971]]]\n",
      "biases : \t [[[ 11.56967144]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26264121 -1.94257971]]]\n",
      "biases : \t [[[ 11.56966386]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26259444 -1.94262648]]]\n",
      "biases : \t [[[ 11.56961709]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26259444 -1.94262648]]]\n",
      "biases : \t [[[ 11.56688415]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26259444 -1.95687739]]]\n",
      "biases : \t [[[ 11.55263325]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26258674 -1.95687739]]]\n",
      "biases : \t [[[ 11.55262554]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26253857 -1.95692555]]]\n",
      "biases : \t [[[ 11.55257738]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26253857 -1.95692555]]]\n",
      "biases : \t [[[ 11.54980157]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26253857 -1.97157719]]]\n",
      "biases : \t [[[ 11.53514993]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26253074 -1.97157719]]]\n",
      "biases : \t [[[ 11.5351421]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26248111 -1.97162682]]]\n",
      "biases : \t [[[ 11.53509247]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26248111 -1.97162682]]]\n",
      "biases : \t [[[ 11.53227197]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26248111 -1.98670156]]]\n",
      "biases : \t [[[ 11.51719723]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26247315 -1.98670156]]]\n",
      "biases : \t [[[ 11.51718927]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26242195 -1.98675276]]]\n",
      "biases : \t [[[ 11.51713807]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26242195 -1.98675276]]]\n",
      "biases : \t [[[ 11.51427095]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26242195 -2.00227487]]]\n",
      "biases : \t [[[ 11.49874884]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26241385 -2.00227487]]]\n",
      "biases : \t [[[ 11.49874073]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26236101 -2.00232771]]]\n",
      "biases : \t [[[ 11.49868789]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26236101 -2.00232771]]]\n",
      "biases : \t [[[ 11.49577206]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26236101 -2.01832358]]]\n",
      "biases : \t [[[ 11.47977618]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26235276 -2.01832358]]]\n",
      "biases : \t [[[ 11.47976793]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26229816 -2.01837819]]]\n",
      "biases : \t [[[ 11.47971333]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26229816 -2.01837819]]]\n",
      "biases : \t [[[ 11.47674655]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26229816 -2.03487658]]]\n",
      "biases : \t [[[ 11.46024816]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26228975 -2.03487658]]]\n",
      "biases : \t [[[ 11.46023975]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26223328 -2.03493305]]]\n",
      "biases : \t [[[ 11.46018328]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26223328 -2.03493305]]]\n",
      "biases : \t [[[ 11.45716313]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26223328 -2.05196539]]]\n",
      "biases : \t [[[ 11.44013079]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26222472 -2.05196539]]]\n",
      "biases : \t [[[ 11.44012223]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26216625 -2.05202386]]]\n",
      "biases : \t [[[ 11.44006376]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26216625 -2.05202386]]]\n",
      "biases : \t [[[ 11.43698765]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26216625 -2.06962457]]]\n",
      "biases : \t [[[ 11.41938693]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26215752 -2.06962457]]]\n",
      "biases : \t [[[ 11.4193782]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26209692 -2.06968517]]]\n",
      "biases : \t [[[ 11.4193176]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26209692 -2.06968517]]]\n",
      "biases : \t [[[ 11.4161827]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26209692 -2.08789208]]]\n",
      "biases : \t [[[ 11.39797579]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.262088   -2.08789208]]]\n",
      "biases : \t [[[ 11.39796688]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26202512 -2.08795497]]]\n",
      "biases : \t [[[ 11.39790399]]] \n",
      "\n",
      "for training data :  [0 0 0]\n",
      "weights : \t [[[ 6.26202512 -2.08795497]]]\n",
      "biases : \t [[[ 11.39470724]]] \n",
      "\n",
      "for training data :  [0 1 1]\n",
      "weights : \t [[[ 6.26202512 -2.10680974]]]\n",
      "biases : \t [[[ 11.37585247]]] \n",
      "\n",
      "for training data :  [1 0 1]\n",
      "weights : \t [[[ 6.26201602 -2.10680974]]]\n",
      "biases : \t [[[ 11.37584338]]] \n",
      "\n",
      "for training data :  [1 1 1]\n",
      "weights : \t [[[ 6.26195068 -2.10687508]]]\n",
      "biases : \t [[[ 11.37577803]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = net.GD(training_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04819164]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
